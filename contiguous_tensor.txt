PyTorch의 텐서에는 텐서의 내용을 실제로 변경하지 않고, 인덱스만 바꿔 동작을 처리하는 함수들이 있습니다.
이러한 작업에는 다음이 포함됩니다.

narrow(), view(), expand() and transpose()

예를 들어, transpose() 를 호출하면 PyTorch 는 새로운 레이아웃으로 새로운 텐서를 생성하지 않고,
Tensor 객체에서 메타 정보를 수정하기 때문에 offset과 stride 가 새로운 모양을 갖습니다.
바뀐 텐서와 원래 텐서는 실제로 메모리를 공유하고 있습니다.

x는 연속적이지만 y는 메모리 레이아웃이 처음부터 같은 모양의 텐서와 다르기 때문에 아닙니다.
"연속적인"이라는 단어는 텐서의 내용이 연결이 끊어진 메모리 블록 주위에 퍼져 있지 않기 때문에 약간 오해의 소지가 있습니다.
여기서 바이트는 여전히 하나의 메모리 블록에 할당되지만 요소의 순서는 다릅니다.

contiguous() 를 호출하면 실제로 텐서의 복사본이 만들어 지므로 요소의 순서는 같은 모양의 텐서가 처음부터 만들어진 것처럼 같습니다.

torch.contiguous() : 특정 축을 잘라내기

x = torch.arange(1*2*2*6).view(-1,2,2,6)
print(x)
x = x.view(-1, 6)
print(x)
x = x[:,:4].contiguous()
print(x)
x=x.view(-1,2)
print(x)

결과
x:
tensor([[[[ 0, 1, 2, 3, 4, 5],
[6, 7, 8, 9, 10, 11]],

[[12, 13, 14, 15, 16, 17],
[18, 19, 20, 21, 22, 23]]]])

x.view(-1, 6):
tensor([[ 0, 1, 2, 3, 4, 5],
[ 6, 7, 8, 9, 10, 11],
[12, 13, 14, 15, 16, 17],
[18, 19, 20, 21, 22, 23]])

x[:,:4].contiguous():
tensor([[ 0, 1, 2, 3],
[6, 7, 8, 9],
[12, 13, 14, 15],
[18, 19, 20, 21]])

x.view(-1, 2):
tensor([[ 0, 1],
[ 2, 3],
[6, 7],
[8, 9],
[12, 13],
[14, 15],
[18, 19],
[20, 21]])

...

 x_reshaped = x.contiguous().view(-1, x.size(-1)) # view 함수를 써서 텐서 모양을 고칠 때
        # contiguous 형식이 요구되는데 view 함수는 메모리 복사없이 이루어집니다.
